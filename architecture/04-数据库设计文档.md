# IntelliKnowledge-RAG 数据库设计文档

## 1. 数据库架构概览

### 1.1 多数据库架构

```
┌────────────────────────────────────────────────────────────────┐
│                      Application Layer                         │
└────────┬───────────────┬───────────────┬──────────────────────┘
         │               │               │
    ┌────▼────┐    ┌────▼────┐    ┌────▼────┐
    │PostgreSQL│    │  Milvus  │    │  Neo4j  │
    │(Metadata)│    │ (Vectors)│    │ (Graph) │
    └─────────┘    └─────────┘    └─────────┘
         │               │               │
         └───────────────┴───────────────┘
                       │
                  ┌────▼────┐
                  │  Redis  │
                  │ (Cache) │
                  └─────────┘
```

### 1.2 数据库选型说明

| 数据库 | 用途 | 理由 |
|--------|------|------|
| **PostgreSQL** | 关系数据、元数据 | JSONB支持、ACID事务、成熟稳定 |
| **Milvus** | 向量存储与检索 | 高性能、支持大规模向量、GPU加速 |
| **Neo4j** | 知识图谱 | 原生图存储、Cypher查询、可视化 |
| **Redis** | 缓存、会话 | 高速读写、支持多种数据结构 |
| **MinIO/S3** | 文件存储 | 对象存储、分布式、成本低 |

---

## 2. PostgreSQL 数据库设计

### 2.1 ER图

```
┌─────────┐       ┌──────────────┐       ┌──────────┐
│  Users  │──┐    │ Collections  │──┐    │Documents │
└─────────┘  │    └──────────────┘  │    └──────────┘
             │                       │         │
             │    ┌──────────────┐  │         │
             └───>│   Ownership  │<─┘         │
                  └──────────────┘            │
                                              │
                  ┌──────────────┐            │
                  │    Chunks    │<───────────┘
                  └──────────────┘
                         │
                  ┌──────▼───────┐
                  │ Conversations│
                  └──────────────┘
                         │
                  ┌──────▼───────┐
                  │   Messages   │
                  └──────────────┘
```

### 2.2 表结构设计

#### 2.2.1 用户表 (users)

```sql
CREATE TABLE users (
    -- 主键
    id BIGSERIAL PRIMARY KEY,

    -- 基本信息
    username VARCHAR(100) UNIQUE NOT NULL,
    email VARCHAR(255) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,

    -- 角色与权限
    role VARCHAR(20) DEFAULT 'user' CHECK (role IN ('user', 'admin', 'guest')),
    permissions JSONB DEFAULT '[]'::jsonb,

    -- 个人信息
    full_name VARCHAR(200),
    avatar_url TEXT,
    bio TEXT,

    -- API配置（加密存储）
    api_keys JSONB DEFAULT '{}'::jsonb,  -- {provider: encrypted_key}

    -- 配额与限制
    quota JSONB DEFAULT '{
        "max_collections": 10,
        "max_documents": 1000,
        "max_storage_mb": 5000,
        "max_queries_per_day": 1000
    }'::jsonb,

    -- 使用统计
    stats JSONB DEFAULT '{
        "total_queries": 0,
        "total_tokens": 0,
        "total_documents": 0
    }'::jsonb,

    -- 状态
    status VARCHAR(20) DEFAULT 'active' CHECK (status IN ('active', 'suspended', 'deleted')),
    email_verified BOOLEAN DEFAULT FALSE,
    verification_token VARCHAR(255),

    -- 时间戳
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    last_login_at TIMESTAMP WITH TIME ZONE,

    -- 索引
    CONSTRAINT email_format CHECK (email ~* '^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}$')
);

-- 索引
CREATE INDEX idx_users_email ON users(email);
CREATE INDEX idx_users_username ON users(username);
CREATE INDEX idx_users_status ON users(status);

-- 更新时间触发器
CREATE TRIGGER update_users_updated_at
BEFORE UPDATE ON users
FOR EACH ROW
EXECUTE FUNCTION update_updated_at_column();
```

#### 2.2.2 知识库表 (collections)

```sql
CREATE TABLE collections (
    -- 主键
    id BIGSERIAL PRIMARY KEY,

    -- 基本信息
    name VARCHAR(200) NOT NULL,
    description TEXT,
    icon VARCHAR(50),  -- emoji或图标标识
    color VARCHAR(20),  -- 主题色

    -- 所有者
    user_id BIGINT NOT NULL,

    -- 可见性
    is_public BOOLEAN DEFAULT FALSE,
    share_token VARCHAR(100) UNIQUE,  -- 分享链接token

    -- 配置
    settings JSONB DEFAULT '{
        "embedding_model": "text-embedding-3-large",
        "chunk_size": 512,
        "chunk_overlap": 50,
        "chunk_strategy": "semantic",
        "enable_ocr": true,
        "enable_knowledge_graph": true,
        "languages": ["zh", "en"]
    }'::jsonb,

    -- 统计信息
    document_count INT DEFAULT 0,
    chunk_count INT DEFAULT 0,
    total_size_mb NUMERIC(10,2) DEFAULT 0,

    -- 标签
    tags TEXT[] DEFAULT ARRAY[]::TEXT[],

    -- 时间戳
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    last_accessed_at TIMESTAMP WITH TIME ZONE,

    -- 外键
    CONSTRAINT fk_collections_user FOREIGN KEY (user_id)
        REFERENCES users(id) ON DELETE CASCADE
);

-- 索引
CREATE INDEX idx_collections_user ON collections(user_id);
CREATE INDEX idx_collections_tags ON collections USING GIN(tags);
CREATE INDEX idx_collections_public ON collections(is_public) WHERE is_public = TRUE;

-- 全文搜索索引
CREATE INDEX idx_collections_search ON collections
    USING GIN(to_tsvector('english', name || ' ' || COALESCE(description, '')));
```

#### 2.2.3 文档表 (documents)

```sql
CREATE TABLE documents (
    -- 主键
    id BIGSERIAL PRIMARY KEY,

    -- 基本信息
    title VARCHAR(500),
    file_name VARCHAR(255) NOT NULL,
    file_type VARCHAR(50) NOT NULL,  -- pdf, markdown, docx, etc.
    file_size BIGINT NOT NULL,  -- bytes
    file_hash VARCHAR(64) UNIQUE NOT NULL,  -- SHA-256哈希，用于去重

    -- 存储信息
    storage_path TEXT NOT NULL,  -- 对象存储路径
    thumbnail_path TEXT,  -- 缩略图路径

    -- 关联
    collection_id BIGINT NOT NULL,
    user_id BIGINT NOT NULL,

    -- 处理状态
    status VARCHAR(20) DEFAULT 'pending'
        CHECK (status IN ('pending', 'processing', 'completed', 'failed')),
    progress INT DEFAULT 0 CHECK (progress >= 0 AND progress <= 100),
    error_message TEXT,

    -- 元数据
    metadata JSONB DEFAULT '{}'::jsonb,
    /*
    示例元数据：
    {
        "author": "John Doe",
        "created_date": "2024-01-01",
        "tags": ["AI", "RAG"],
        "language": "zh-CN",
        "page_count": 50,
        "word_count": 10000,
        "source": "upload",
        "source_url": "https://..."
    }
    */

    -- 内容统计
    chunk_count INT DEFAULT 0,
    token_count INT DEFAULT 0,
    entity_count INT DEFAULT 0,

    -- 处理时间
    processing_started_at TIMESTAMP WITH TIME ZONE,
    processing_completed_at TIMESTAMP WITH TIME ZONE,
    processing_duration_seconds NUMERIC(10,2),

    -- 时间戳
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),

    -- 外键
    CONSTRAINT fk_documents_collection FOREIGN KEY (collection_id)
        REFERENCES collections(id) ON DELETE CASCADE,
    CONSTRAINT fk_documents_user FOREIGN KEY (user_id)
        REFERENCES users(id) ON DELETE CASCADE
);

-- 索引
CREATE INDEX idx_documents_collection ON documents(collection_id);
CREATE INDEX idx_documents_user ON documents(user_id);
CREATE INDEX idx_documents_status ON documents(status);
CREATE INDEX idx_documents_hash ON documents(file_hash);
CREATE INDEX idx_documents_metadata ON documents USING GIN(metadata);
CREATE INDEX idx_documents_created ON documents(created_at DESC);

-- 全文搜索
CREATE INDEX idx_documents_search ON documents
    USING GIN(to_tsvector('english', title || ' ' || file_name));

-- 统计触发器：更新collection的文档计数
CREATE OR REPLACE FUNCTION update_collection_stats()
RETURNS TRIGGER AS $$
BEGIN
    IF TG_OP = 'INSERT' THEN
        UPDATE collections
        SET document_count = document_count + 1,
            total_size_mb = total_size_mb + (NEW.file_size / 1048576.0)
        WHERE id = NEW.collection_id;
    ELSIF TG_OP = 'DELETE' THEN
        UPDATE collections
        SET document_count = document_count - 1,
            total_size_mb = total_size_mb - (OLD.file_size / 1048576.0)
        WHERE id = OLD.collection_id;
    END IF;
    RETURN NULL;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER trigger_update_collection_stats
AFTER INSERT OR DELETE ON documents
FOR EACH ROW
EXECUTE FUNCTION update_collection_stats();
```

#### 2.2.4 文档块表 (chunks)

```sql
CREATE TABLE chunks (
    -- 主键
    id BIGSERIAL PRIMARY KEY,

    -- 关联
    document_id BIGINT NOT NULL,
    collection_id BIGINT NOT NULL,

    -- 块信息
    chunk_index INT NOT NULL,  -- 在文档中的索引
    text TEXT NOT NULL,
    token_count INT NOT NULL,

    -- 向量信息
    embedding_id VARCHAR(100),  -- Milvus中的向量ID
    embedding_model VARCHAR(100),

    -- 位置信息
    page_number INT,
    section_title VARCHAR(500),
    start_char_index INT,
    end_char_index INT,

    -- 元数据
    metadata JSONB DEFAULT '{}'::jsonb,
    /*
    {
        "chunk_type": "text|table|image",
        "parent_chunk_id": 123,
        "child_chunk_ids": [124, 125],
        "heading_level": 2,
        "list_item": false
    }
    */

    -- BM25关键词提取
    keywords TEXT[],

    -- 时间戳
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),

    -- 外键
    CONSTRAINT fk_chunks_document FOREIGN KEY (document_id)
        REFERENCES documents(id) ON DELETE CASCADE,
    CONSTRAINT fk_chunks_collection FOREIGN KEY (collection_id)
        REFERENCES collections(id) ON DELETE CASCADE,

    -- 唯一约束
    CONSTRAINT unique_document_chunk UNIQUE (document_id, chunk_index)
);

-- 索引
CREATE INDEX idx_chunks_document ON chunks(document_id);
CREATE INDEX idx_chunks_collection ON chunks(collection_id);
CREATE INDEX idx_chunks_embedding ON chunks(embedding_id);
CREATE INDEX idx_chunks_keywords ON chunks USING GIN(keywords);

-- 全文搜索索引
CREATE INDEX idx_chunks_text_search ON chunks
    USING GIN(to_tsvector('english', text));

-- 分区策略（按collection_id）
-- 适合大规模数据场景
-- CREATE TABLE chunks_collection_1 PARTITION OF chunks
--     FOR VALUES IN (1);
```

#### 2.2.5 对话表 (conversations)

```sql
CREATE TABLE conversations (
    -- 主键
    id BIGSERIAL PRIMARY KEY,

    -- 基本信息
    title VARCHAR(500),

    -- 关联
    user_id BIGINT NOT NULL,
    collection_id BIGINT,  -- 可选，可以跨多个知识库对话

    -- 配置
    config JSONB DEFAULT '{
        "model": "gpt-4-turbo",
        "temperature": 0.7,
        "max_tokens": 2000,
        "enable_reflection": true
    }'::jsonb,

    -- 统计
    message_count INT DEFAULT 0,
    total_tokens INT DEFAULT 0,
    total_cost NUMERIC(10,4) DEFAULT 0,

    -- 状态
    status VARCHAR(20) DEFAULT 'active'
        CHECK (status IN ('active', 'archived', 'deleted')),

    -- 时间戳
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    last_message_at TIMESTAMP WITH TIME ZONE,

    -- 外键
    CONSTRAINT fk_conversations_user FOREIGN KEY (user_id)
        REFERENCES users(id) ON DELETE CASCADE,
    CONSTRAINT fk_conversations_collection FOREIGN KEY (collection_id)
        REFERENCES collections(id) ON DELETE SET NULL
);

-- 索引
CREATE INDEX idx_conversations_user ON conversations(user_id);
CREATE INDEX idx_conversations_collection ON conversations(collection_id);
CREATE INDEX idx_conversations_updated ON conversations(updated_at DESC);
CREATE INDEX idx_conversations_status ON conversations(status);
```

#### 2.2.6 消息表 (messages)

```sql
CREATE TABLE messages (
    -- 主键
    id BIGSERIAL PRIMARY KEY,

    -- 关联
    conversation_id BIGINT NOT NULL,
    user_id BIGINT NOT NULL,

    -- 消息内容
    role VARCHAR(20) NOT NULL CHECK (role IN ('user', 'assistant', 'system')),
    content TEXT NOT NULL,

    -- 检索上下文
    retrieved_chunks JSONB,  -- [{chunk_id, score, text}, ...]
    /*
    [
        {
            "chunk_id": 50001,
            "document_id": 1001,
            "score": 0.92,
            "text": "...",
            "page_number": 5
        }
    ]
    */

    -- Agent执行轨迹
    agent_trace JSONB,
    /*
    {
        "planning": {"sub_queries": [...]},
        "retrieval": {"iterations": 2, "total_docs": 15},
        "reflection": {"confidence": 0.88, "issues": []},
        "tools_used": ["search", "calculator"]
    }
    */

    -- 元数据
    metadata JSONB DEFAULT '{}'::jsonb,
    /*
    {
        "model": "gpt-4-turbo",
        "tokens": 450,
        "cost": 0.009,
        "latency_ms": 1200,
        "confidence": 0.88
    }
    */

    -- 反馈
    feedback JSONB,  -- {"rating": 5, "comment": "很有帮助"}

    -- 时间戳
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),

    -- 外键
    CONSTRAINT fk_messages_conversation FOREIGN KEY (conversation_id)
        REFERENCES conversations(id) ON DELETE CASCADE,
    CONSTRAINT fk_messages_user FOREIGN KEY (user_id)
        REFERENCES users(id) ON DELETE CASCADE
);

-- 索引
CREATE INDEX idx_messages_conversation ON messages(conversation_id, created_at);
CREATE INDEX idx_messages_user ON messages(user_id);
CREATE INDEX idx_messages_created ON messages(created_at DESC);

-- 分区策略（按月分区）
-- CREATE TABLE messages_2025_01 PARTITION OF messages
--     FOR VALUES FROM ('2025-01-01') TO ('2025-02-01');
```

#### 2.2.7 权限表 (permissions)

```sql
CREATE TABLE collection_permissions (
    id BIGSERIAL PRIMARY KEY,

    -- 关联
    collection_id BIGINT NOT NULL,
    user_id BIGINT NOT NULL,

    -- 权限
    permission VARCHAR(20) NOT NULL
        CHECK (permission IN ('read', 'write', 'admin')),

    -- 授权信息
    granted_by BIGINT,  -- 授权者
    granted_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    expires_at TIMESTAMP WITH TIME ZONE,

    -- 外键
    CONSTRAINT fk_permissions_collection FOREIGN KEY (collection_id)
        REFERENCES collections(id) ON DELETE CASCADE,
    CONSTRAINT fk_permissions_user FOREIGN KEY (user_id)
        REFERENCES users(id) ON DELETE CASCADE,
    CONSTRAINT fk_permissions_granter FOREIGN KEY (granted_by)
        REFERENCES users(id) ON DELETE SET NULL,

    -- 唯一约束
    CONSTRAINT unique_collection_user UNIQUE (collection_id, user_id)
);

CREATE INDEX idx_permissions_collection ON collection_permissions(collection_id);
CREATE INDEX idx_permissions_user ON collection_permissions(user_id);
```

#### 2.2.8 审计日志表 (audit_logs)

```sql
CREATE TABLE audit_logs (
    id BIGSERIAL PRIMARY KEY,

    -- 用户信息
    user_id BIGINT,
    username VARCHAR(100),
    ip_address INET,

    -- 操作信息
    action VARCHAR(100) NOT NULL,  -- 'document.upload', 'query.execute', etc.
    resource_type VARCHAR(50),  -- 'document', 'collection', etc.
    resource_id BIGINT,

    -- 详细信息
    details JSONB,

    -- 结果
    status VARCHAR(20) CHECK (status IN ('success', 'failure')),
    error_message TEXT,

    -- 时间戳
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- 索引
CREATE INDEX idx_audit_user ON audit_logs(user_id, created_at DESC);
CREATE INDEX idx_audit_action ON audit_logs(action);
CREATE INDEX idx_audit_resource ON audit_logs(resource_type, resource_id);
CREATE INDEX idx_audit_created ON audit_logs(created_at DESC);

-- 自动分区（按月）
CREATE TABLE audit_logs_2025_12 PARTITION OF audit_logs
    FOR VALUES FROM ('2025-12-01') TO ('2026-01-01');
```

---

## 3. Milvus 向量数据库设计

### 3.1 Collection Schema

```python
from pymilvus import CollectionSchema, FieldSchema, DataType

# 定义字段
fields = [
    # 主键（自动生成）
    FieldSchema(
        name="id",
        dtype=DataType.INT64,
        is_primary=True,
        auto_id=True
    ),

    # 关联ID
    FieldSchema(
        name="chunk_id",
        dtype=DataType.INT64,
        description="PostgreSQL中的chunk ID"
    ),
    FieldSchema(
        name="document_id",
        dtype=DataType.INT64
    ),
    FieldSchema(
        name="collection_id",
        dtype=DataType.INT64
    ),

    # 向量
    FieldSchema(
        name="embedding",
        dtype=DataType.FLOAT_VECTOR,
        dim=1536  # text-embedding-3-large
    ),

    # 文本内容（用于结果返回）
    FieldSchema(
        name="text",
        dtype=DataType.VARCHAR,
        max_length=5000
    ),

    # 元数据（JSON格式）
    FieldSchema(
        name="metadata",
        dtype=DataType.JSON
    ),

    # 时间戳
    FieldSchema(
        name="created_at",
        dtype=DataType.INT64,
        description="Unix timestamp"
    )
]

# 创建Schema
schema = CollectionSchema(
    fields=fields,
    description="Document chunks with embeddings",
    enable_dynamic_field=True  # 允许动态字段
)

# 创建Collection
from pymilvus import Collection

collection = Collection(
    name="intelliknowledge_chunks",
    schema=schema,
    using="default"
)
```

### 3.2 索引配置

```python
# HNSW索引（高性能）
index_params = {
    "metric_type": "COSINE",  # 余弦相似度
    "index_type": "HNSW",
    "params": {
        "M": 16,  # 每个节点的邻居数（越大越精确但越慢）
        "efConstruction": 200  # 构建时的候选集大小
    }
}

collection.create_index(
    field_name="embedding",
    index_params=index_params
)

# 为collection_id创建标量索引（用于过滤）
collection.create_index(
    field_name="collection_id",
    index_params={"index_type": "STL_SORT"}
)
```

### 3.3 分区策略

```python
# 按collection_id分区（提高查询性能）
collection.create_partition("collection_10")
collection.create_partition("collection_11")

# 插入数据到指定分区
collection.insert(
    data=[...],
    partition_name="collection_10"
)

# 查询指定分区
results = collection.search(
    data=[query_embedding],
    anns_field="embedding",
    param={"metric_type": "COSINE", "params": {"ef": 100}},
    limit=10,
    partition_names=["collection_10"]
)
```

### 3.4 查询示例

```python
# 向量检索
search_params = {
    "metric_type": "COSINE",
    "params": {
        "ef": 100  # 搜索时的候选集大小（越大越精确）
    }
}

results = collection.search(
    data=[query_embedding],
    anns_field="embedding",
    param=search_params,
    limit=10,
    expr="collection_id == 10",  # 过滤表达式
    output_fields=["chunk_id", "text", "metadata"]
)

# 结果处理
for hits in results:
    for hit in hits:
        print(f"Chunk ID: {hit.entity.get('chunk_id')}")
        print(f"Score: {hit.distance}")
        print(f"Text: {hit.entity.get('text')}")
```

---

## 4. Neo4j 知识图谱设计

### 4.1 图模型

```cypher
// 节点类型定义

// 实体节点
(:Entity {
    id: string,
    name: string,
    type: string,  // Person, Organization, Location, Concept, Technology
    description: string,
    properties: map,
    mention_count: int,
    created_at: datetime
})

// 文档节点
(:Document {
    id: int,  // 对应PostgreSQL的document_id
    title: string,
    file_type: string,
    collection_id: int
})

// 概念节点
(:Concept {
    name: string,
    category: string,
    description: string
})

// 关系类型定义

// 实体关系
(:Entity)-[:RELATED_TO {
    weight: float,
    relation_type: string,
    source_document: int,
    confidence: float
}]->(:Entity)

// 文档中提及
(:Entity)-[:MENTIONED_IN {
    count: int,
    positions: [int],  // 出现位置
    context: [string]  // 上下文片段
}]->(:Document)

// 概念层级
(:Concept)-[:IS_A {
    confidence: float
}]->(:Concept)

// 实体属性
(:Entity)-[:HAS_ATTRIBUTE {
    attribute: string,
    value: string
}]->(:Entity)

// 共现关系
(:Entity)-[:CO_OCCURS_WITH {
    frequency: int,
    documents: [int]
}]->(:Entity)
```

### 4.2 索引与约束

```cypher
-- 唯一约束
CREATE CONSTRAINT entity_id_unique
ON (e:Entity) ASSERT e.id IS UNIQUE;

CREATE CONSTRAINT document_id_unique
ON (d:Document) ASSERT d.id IS UNIQUE;

-- 全文索引
CREATE FULLTEXT INDEX entity_name_fulltext
FOR (e:Entity) ON EACH [e.name, e.description];

CREATE FULLTEXT INDEX concept_name_fulltext
FOR (c:Concept) ON EACH [c.name, c.description];

-- 属性索引
CREATE INDEX entity_type_index
FOR (e:Entity) ON (e.type);

CREATE INDEX document_collection_index
FOR (d:Document) ON (d.collection_id);
```

### 4.3 常用查询模式

#### 4.3.1 查找实体关系

```cypher
// 查找LangChain的所有关系
MATCH (e:Entity {name: "LangChain"})-[r]-(related)
RETURN e, r, related
LIMIT 50;

// 查找两个实体之间的最短路径
MATCH path = shortestPath(
    (e1:Entity {name: "LangChain"})-[*..5]-(e2:Entity {name: "RAG"})
)
RETURN path;

// 查找实体的N跳邻居
MATCH (e:Entity {name: "LangChain"})-[*1..2]-(neighbor)
RETURN DISTINCT neighbor.name, neighbor.type
LIMIT 20;
```

#### 4.3.2 社区发现

```cypher
// 使用Louvain算法进行社区发现
CALL gds.louvain.stream({
    nodeProjection: 'Entity',
    relationshipProjection: {
        RELATED_TO: {
            type: 'RELATED_TO',
            properties: 'weight',
            orientation: 'UNDIRECTED'
        }
    },
    relationshipWeightProperty: 'weight'
})
YIELD nodeId, communityId
RETURN gds.util.asNode(nodeId).name AS entity, communityId
ORDER BY communityId;
```

#### 4.3.3 中心性分析

```cypher
// PageRank：找出最重要的实体
CALL gds.pageRank.stream({
    nodeProjection: 'Entity',
    relationshipProjection: 'RELATED_TO'
})
YIELD nodeId, score
RETURN gds.util.asNode(nodeId).name AS entity, score
ORDER BY score DESC
LIMIT 20;
```

### 4.4 数据导入

```python
from neo4j import GraphDatabase

class KnowledgeGraphDB:
    def __init__(self, uri, user, password):
        self.driver = GraphDatabase.driver(uri, auth=(user, password))

    def create_entity(self, entity_id, name, entity_type, properties=None):
        with self.driver.session() as session:
            session.run("""
                MERGE (e:Entity {id: $entity_id})
                SET e.name = $name,
                    e.type = $entity_type,
                    e.properties = $properties,
                    e.created_at = datetime()
                """,
                entity_id=entity_id,
                name=name,
                entity_type=entity_type,
                properties=properties or {}
            )

    def create_relation(self, entity1_id, entity2_id, relation_type, properties=None):
        with self.driver.session() as session:
            session.run("""
                MATCH (e1:Entity {id: $entity1_id})
                MATCH (e2:Entity {id: $entity2_id})
                MERGE (e1)-[r:RELATED_TO]->(e2)
                SET r.relation_type = $relation_type,
                    r.weight = $weight,
                    r.confidence = $confidence
                """,
                entity1_id=entity1_id,
                entity2_id=entity2_id,
                relation_type=relation_type,
                weight=properties.get('weight', 1.0),
                confidence=properties.get('confidence', 1.0)
            )
```

---

## 5. Redis 缓存设计

### 5.1 缓存策略

| Key Pattern | 数据类型 | TTL | 用途 |
|-------------|----------|-----|------|
| `user:{user_id}` | Hash | 1h | 用户信息缓存 |
| `collection:{id}` | Hash | 30m | 知识库信息缓存 |
| `embedding:{text_hash}` | String | 24h | Embedding结果缓存 |
| `query:{query_hash}:{collection_id}` | String | 1h | 查询结果缓存 |
| `session:{token}` | String | 24h | 会话信息 |
| `rate_limit:{user_id}:{endpoint}` | String | 1m | 速率限制 |
| `hot_documents:{collection_id}` | ZSet | 24h | 热门文档排行 |

### 5.2 数据结构示例

```python
import redis
import json
import hashlib

class CacheManager:
    def __init__(self, redis_client):
        self.redis = redis_client

    # Embedding缓存
    def cache_embedding(self, text, embedding, ttl=86400):
        key = f"embedding:{self._hash(text)}"
        self.redis.setex(
            key,
            ttl,
            json.dumps(embedding)
        )

    def get_embedding(self, text):
        key = f"embedding:{self._hash(text)}"
        cached = self.redis.get(key)
        return json.loads(cached) if cached else None

    # 查询结果缓存
    def cache_query_result(self, query, collection_id, result, ttl=3600):
        key = f"query:{self._hash(query)}:{collection_id}"
        self.redis.setex(
            key,
            ttl,
            json.dumps(result)
        )

    # 热门文档统计
    def increment_document_view(self, collection_id, document_id):
        key = f"hot_documents:{collection_id}"
        self.redis.zincrby(key, 1, document_id)
        self.redis.expire(key, 86400)

    def get_hot_documents(self, collection_id, limit=10):
        key = f"hot_documents:{collection_id}"
        return self.redis.zrevrange(key, 0, limit-1, withscores=True)

    # 速率限制
    def check_rate_limit(self, user_id, endpoint, limit=60, window=60):
        key = f"rate_limit:{user_id}:{endpoint}"
        current = self.redis.incr(key)
        if current == 1:
            self.redis.expire(key, window)
        return current <= limit

    @staticmethod
    def _hash(text):
        return hashlib.sha256(text.encode()).hexdigest()[:16]
```

---

## 6. 数据迁移与备份

### 6.1 数据库迁移

```sql
-- 使用Flyway或Alembic进行版本管理

-- V001__initial_schema.sql
CREATE TABLE users (...);
CREATE TABLE collections (...);
...

-- V002__add_audit_logs.sql
CREATE TABLE audit_logs (...);

-- V003__add_permissions.sql
CREATE TABLE collection_permissions (...);
```

### 6.2 备份策略

#### PostgreSQL备份

```bash
# 每日全量备份
pg_dump intelliknowledge > backup_$(date +%Y%m%d).sql

# 持续归档（WAL）
# postgresql.conf:
# wal_level = replica
# archive_mode = on
# archive_command = 'cp %p /backup/archive/%f'

# 恢复
psql intelliknowledge < backup_20251204.sql
```

#### Milvus备份

```python
# 导出Collection
from pymilvus import utility

utility.export_collection(
    collection_name="intelliknowledge_chunks",
    output_path="/backup/milvus_backup.bin"
)

# 恢复
utility.import_collection(
    collection_name="intelliknowledge_chunks",
    input_path="/backup/milvus_backup.bin"
)
```

#### Neo4j备份

```bash
# 停止Neo4j
neo4j stop

# 备份
neo4j-admin dump --database=neo4j --to=/backup/neo4j_backup.dump

# 恢复
neo4j-admin load --database=neo4j --from=/backup/neo4j_backup.dump
```

---

## 7. 性能优化

### 7.1 查询优化

```sql
-- 使用EXPLAIN ANALYZE分析查询
EXPLAIN ANALYZE
SELECT d.*, c.name AS collection_name
FROM documents d
JOIN collections c ON d.collection_id = c.id
WHERE d.user_id = 1001
    AND d.status = 'completed'
ORDER BY d.created_at DESC
LIMIT 20;

-- 创建复合索引
CREATE INDEX idx_documents_user_status_created
ON documents(user_id, status, created_at DESC);

-- 分区表查询
SELECT * FROM messages
WHERE conversation_id = 5001
    AND created_at >= '2025-12-01'
    AND created_at < '2026-01-01';
```

### 7.2 连接池配置

```python
from sqlalchemy import create_engine
from sqlalchemy.pool import QueuePool

engine = create_engine(
    "postgresql://user:pass@localhost/intelliknowledge",
    poolclass=QueuePool,
    pool_size=20,  # 连接池大小
    max_overflow=40,  # 最大溢出连接数
    pool_timeout=30,  # 获取连接超时
    pool_recycle=3600  # 连接回收时间
)
```

---

## 8. 监控指标

### 8.1 PostgreSQL监控

```sql
-- 慢查询
SELECT query, mean_exec_time, calls
FROM pg_stat_statements
ORDER BY mean_exec_time DESC
LIMIT 10;

-- 表大小
SELECT
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size
FROM pg_tables
WHERE schemaname = 'public'
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;

-- 索引使用率
SELECT
    schemaname,
    tablename,
    indexname,
    idx_scan,
    idx_tup_read,
    idx_tup_fetch
FROM pg_stat_user_indexes
WHERE idx_scan = 0  -- 未使用的索引
ORDER BY pg_relation_size(indexrelid) DESC;
```

### 8.2 Milvus监控

```python
# 查看Collection统计
stats = collection.get_stats()
print(f"Row count: {stats['row_count']}")
print(f"Index type: {stats['index']}")

# 查询性能
import time
start = time.time()
results = collection.search(...)
latency = (time.time() - start) * 1000
print(f"Search latency: {latency}ms")
```

---

**文档版本**：v1.0
**最后更新**：2025-12-04
